{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "909ea486-a2f0-4d2e-b9be-18eeb19840b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler uploaded to S3 at: s3://dandadan/scaler/scaler.pkl\n",
      "Scaled training data uploaded to S3 at: s3://dandadan/train/train_scaled.csv\n",
      "Scaled test data uploaded to S3 at: s3://dandadan/test/test_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "# Dataset modeling prerequisites\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Initialize S3 details\n",
    "BUCKET_URI = \"s3://dandadan\"\n",
    "BUCKET_NAME = \"dandadan\"\n",
    "DATASET_PATH = f\"{BUCKET_URI}/mobile_features_ds.csv\"\n",
    "\n",
    "# Initialize S3 session\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# Load your dataset directly from S3\n",
    "obj = s3.get_object(Bucket=BUCKET_NAME, Key='mobile_features_ds.csv')\n",
    "df = pd.read_csv(obj['Body'])\n",
    "\n",
    "# Encode necessary categorical columns (if any)\n",
    "le = LabelEncoder()\n",
    "categorical_columns = ['clock_speed', 'm_dep']  # Assuming these columns need encoding\n",
    "for col in categorical_columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Define target and features\n",
    "TARGET_NAME = \"price_range\"\n",
    "features_to_scale = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', \n",
    "                     'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', \n",
    "                     'sc_h', 'sc_w', 'talk_time']\n",
    "\n",
    "# Split dataset into features and target\n",
    "X = df.drop(columns=[TARGET_NAME])\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling only to the numerical columns\n",
    "X_train[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "X_test[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "\n",
    "# Save the scaler for future use (during inference)\n",
    "scaler_filename = \"scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "\n",
    "# Upload the scaler to S3\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "scaler_s3_path = f\"{BUCKET_URI}/scaler/scaler.pkl\"\n",
    "s3_resource.Bucket(BUCKET_NAME).upload_file(scaler_filename, \"scaler/scaler.pkl\")\n",
    "print(f\"Scaler uploaded to S3 at: {scaler_s3_path}\")\n",
    "\n",
    "# Save train and test data locally with headers\n",
    "train_file = \"train_scaled.csv\"\n",
    "test_file = \"test_scaled.csv\"\n",
    "pd.concat([pd.DataFrame(y_train).reset_index(drop=True), X_train.reset_index(drop=True)], axis=1).to_csv(train_file, index=False, header=True)\n",
    "pd.concat([pd.DataFrame(y_test).reset_index(drop=True), X_test.reset_index(drop=True)], axis=1).to_csv(test_file, index=False, header=True)\n",
    "\n",
    "# Upload the training and test CSVs to S3\n",
    "train_s3_path = f\"{BUCKET_URI}/train/train_scaled.csv\"\n",
    "test_s3_path = f\"{BUCKET_URI}/test/test_scaled.csv\"\n",
    "s3_resource.Bucket(BUCKET_NAME).upload_file(train_file, \"train/train_scaled.csv\")\n",
    "s3_resource.Bucket(BUCKET_NAME).upload_file(test_file, \"test/test_scaled.csv\")\n",
    "print(f\"Scaled training data uploaded to S3 at: {train_s3_path}\")\n",
    "print(f\"Scaled test data uploaded to S3 at: {test_s3_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "710a3c05-4c8e-44c6-bf9d-539d29e57da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost==1.5.0) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost==1.5.0) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==1.5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287922ef-78dc-4644-9f26-4abbb147fc60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m\n\u001b[1;32m     49\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     50\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb_model,\n\u001b[1;32m     51\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m  \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Fit RandomizedSearchCV on your training data\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters found by Random Search\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters from Random Search:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1230\u001b[0m model, feval, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[1;32m   1231\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1232\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1233\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     label_transform\u001b[38;5;241m=\u001b[39mlabel_transform,\n\u001b[1;32m   1248\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:1677\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtrain, DMatrix):\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid training matrix: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dtrain)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1677\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     _check_call(_LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   1681\u001b[0m                                             ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration),\n\u001b[1;32m   1682\u001b[0m                                             dtrain\u001b[38;5;241m.\u001b[39mhandle))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:2463\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   2460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m   2461\u001b[0m     )\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;66;03m# Booster can't accept data with different feature names\u001b[39;00m\n\u001b[0;32m-> 2463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m!=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m:\n\u001b[1;32m   2464\u001b[0m     dat_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m   2465\u001b[0m     my_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mfeature_names) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:968\u001b[0m, in \u001b[0;36mDMatrix.feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    965\u001b[0m length \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[1;32m    966\u001b[0m sarr \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_char_p)()\n\u001b[1;32m    967\u001b[0m _check_call(\n\u001b[0;32m--> 968\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixGetStrFeatureInfo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeature_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43msarr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m )\n\u001b[1;32m    975\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m from_cstr_to_pystr(sarr, length)\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_names:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#RandomSearch to find best hyper parameters for model training\n",
    "\n",
    "import boto3\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize S3 details\n",
    "BUCKET_NAME = \"dandadan\"\n",
    "DATASET_PATH = 'mobile_features_ds.csv'\n",
    "\n",
    "# Initialize S3 session\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# Load your dataset directly from S3\n",
    "obj = s3.get_object(Bucket=BUCKET_NAME, Key=DATASET_PATH)\n",
    "df = pd.read_csv(obj['Body'])\n",
    "\n",
    "# Define target and features\n",
    "TARGET_NAME = \"price_range\"\n",
    "X = df.drop(columns=[TARGET_NAME])\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "# Encode target labels as integers starting from 0\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Search\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],  # Number of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],  # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7, 9],  # Maximum depth of a tree\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Fraction of samples used per tree\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features used per tree\n",
    "    'gamma': [0, 0.1, 0.5, 1, 2]  # Minimum loss reduction required for further partitioning\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False)  # Add use_label_encoder=False\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Number of random combinations to try\n",
    "    scoring='accuracy',  # Use accuracy as the metric for evaluation\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Print progress\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV on your training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by Random Search\n",
    "print(\"Best Hyperparameters from Random Search:\", random_search.best_params_)\n",
    "\n",
    "# Get the best score achieved with the best hyperparameters\n",
    "print(\"Best Cross-Validation Score Achieved:\", random_search.best_score_)\n",
    "\n",
    "# Use the best estimator (model with best hyperparameters) to predict on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {100 * test_accuracy:.2f} %\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b08a34a-c70d-4b80-aa9c-58f5813f62db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    return joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    input_data_list = json.loads(request_body)\n",
    "    return np.array(input_data_list)\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    prediction = model.predict(input_data)\n",
    "    return prediction.tolist()\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    return json.dumps(prediction)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Extracting arguments...\")\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    # Hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=200)  # Best value from Random Search\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=0.2)  # Best value from Random Search\n",
    "    parser.add_argument(\"--max-depth\", type=int, default=3)  # Best value from Random Search\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.8)  # Best value from Random Search\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.1)  # Best value from Random Search\n",
    "    parser.add_argument(\"--colsample-bytree\", type=float, default=1.0)  # Best value from Random Search\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train_scaled.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test_scaled.csv\")\n",
    "    \n",
    "    # Local path to save the model in the current directory\n",
    "    parser.add_argument(\"--local-model-path\", type=str, default=\"model_local.joblib\")  \n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"Train channel:\", args.train)\n",
    "    print(\"Test channel:\", args.test)\n",
    "\n",
    "    # Load training and testing data\n",
    "    print(\"Reading data...\")\n",
    "    df_train = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    df_test = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    # Check for NaN values\n",
    "    if df_train.isnull().any().any():\n",
    "        raise ValueError(\"Training data contains NaN values.\")\n",
    "\n",
    "    print(\"Building training and testing datasets...\")\n",
    "    TARGET_NAME = \"price_range\"\n",
    "    all_columns_name = [col for col in df_train.columns if col not in [TARGET_NAME, 'id', 'Unnamed: 0']]\n",
    "    \n",
    "    X_train = df_train[all_columns_name]\n",
    "    y_train = df_train[TARGET_NAME].values\n",
    "\n",
    "    # Train model using XGBoost\n",
    "    print(\"Training model...\")\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=args.n_estimators,\n",
    "        learning_rate=args.learning_rate,\n",
    "        max_depth=args.max_depth,\n",
    "        subsample=args.subsample,\n",
    "        gamma=args.gamma,\n",
    "        colsample_bytree=args.colsample_bytree,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        use_label_encoder=False,  # Important for newer versions of XGBoost\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Validate model\n",
    "    print(\"Validating model...\")\n",
    "    bal_acc_train = balanced_accuracy_score(y_train, model.predict(X_train))\n",
    "    y_test = df_test[TARGET_NAME].values\n",
    "    bal_acc_test = balanced_accuracy_score(y_test, model.predict(df_test[all_columns_name]))\n",
    "\n",
    "    print(f\"Train balanced accuracy: {100 * bal_acc_train:.3f} %\")\n",
    "    print(f\"Test balanced accuracy: {100 * bal_acc_test:.3f} %\")\n",
    "\n",
    "    # Persist model to SageMaker model directory\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(\"Model persisted at \" + path)\n",
    "\n",
    "    # Save the model locally in the current directory\n",
    "    local_model_path = os.path.join(os.getcwd(), args.local_model_path)  # Save in the current directory\n",
    "    joblib.dump(model, local_model_path)\n",
    "    print(f\"Model saved locally at {local_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd0163dc-ff90-42e0-8ec6-193b29fc2c68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script uploaded to s3://dandadan/scripts/script.py\n"
     ]
    }
   ],
   "source": [
    "#Loading script file to S3\n",
    "import boto3\n",
    "\n",
    "# Initialize S3 resource\n",
    "s3 = boto3.resource('s3')\n",
    "BUCKET_NAME = 'dandadan'\n",
    "script_file = 'script.py'\n",
    "\n",
    "# Upload the script to S3\n",
    "s3.Bucket(BUCKET_NAME).upload_file(script_file, 'scripts/script.py')\n",
    "print(f'Script uploaded to s3://{BUCKET_NAME}/scripts/{script_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a47e798f-95ad-423b-a9a3-3168601152f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.c5.xlarge.\n",
      "INFO:sagemaker:Creating training-job with name: xgboost-sagemaker-2024-11-20-03-06-55-133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-20 03:06:56 Starting - Starting the training job...\n",
      "2024-11-20 03:07:09 Starting - Preparing the instances for training...\n",
      "2024-11-20 03:07:37 Downloading - Downloading input data...\n",
      "2024-11-20 03:08:07 Downloading - Downloading the training image...\n",
      "2024-11-20 03:08:53 Training - Training image download completed. Training in progress.\n",
      "2024-11-20 03:08:53 Uploading - Uploading generated training model\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2024-11-20 03:08:43.045 ip-10-0-249-87.us-east-2.compute.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-11-20 03:08:43.064 ip-10-0-249-87.us-east-2.compute.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:43:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:43:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:43:INFO] Module script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:43:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:43:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:43:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: script\n",
      "  Building wheel for script (setup.py): started\n",
      "  Building wheel for script (setup.py): finished with status 'done'\n",
      "  Created wheel for script: filename=script-1.0.0-py2.py3-none-any.whl size=5343 sha256=b19687155d27c756fa64f129e69940e1502734426dbf0ec5fe31a07f4c5f1d54\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-vp5g0z05/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built script\u001b[0m\n",
      "\u001b[34mInstalling collected packages: script\u001b[0m\n",
      "\u001b[34mSuccessfully installed script-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-11-20:03:08:45:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"colsample-bytree\": 1.0,\n",
      "        \"gamma\": 0.1,\n",
      "        \"learning-rate\": 0.2,\n",
      "        \"max-depth\": 3,\n",
      "        \"n-estimators\": 200,\n",
      "        \"subsample\": 0.8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"xgboost-sagemaker-2024-11-20-03-06-55-133\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-872515256694/xgboost-sagemaker-2024-11-20-03-06-55-133/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"colsample-bytree\":1.0,\"gamma\":0.1,\"learning-rate\":0.2,\"max-depth\":3,\"n-estimators\":200,\"subsample\":0.8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-872515256694/xgboost-sagemaker-2024-11-20-03-06-55-133/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"colsample-bytree\":1.0,\"gamma\":0.1,\"learning-rate\":0.2,\"max-depth\":3,\"n-estimators\":200,\"subsample\":0.8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgboost-sagemaker-2024-11-20-03-06-55-133\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-872515256694/xgboost-sagemaker-2024-11-20-03-06-55-133/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--colsample-bytree\",\"1.0\",\"--gamma\",\"0.1\",\"--learning-rate\",\"0.2\",\"--max-depth\",\"3\",\"--n-estimators\",\"200\",\"--subsample\",\"0.8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_COLSAMPLE-BYTREE=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_MAX-DEPTH=3\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=200\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m script --colsample-bytree 1.0 --gamma 0.1 --learning-rate 0.2 --max-depth 3 --n-estimators 200 --subsample 0.8\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34mExtracting arguments...\u001b[0m\n",
      "\u001b[34mTrain channel: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mTest channel: /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mReading data...\u001b[0m\n",
      "\u001b[34mBuilding training and testing datasets...\u001b[0m\n",
      "\u001b[34mTraining model...\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\u001b[0m\n",
      "\u001b[34mValidating model...\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\u001b[0m\n",
      "\u001b[34mTrain balanced accuracy: 100.000 %\u001b[0m\n",
      "\u001b[34mTest balanced accuracy: 92.169 %\u001b[0m\n",
      "\u001b[34mModel persisted at /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34mModel saved locally at /opt/ml/code/model_local.joblib\u001b[0m\n",
      "\n",
      "2024-11-20 03:09:06 Completed - Training job completed\n",
      "Training seconds: 89\n",
      "Billable seconds: 32\n",
      "Managed Spot Training savings: 64.0%\n"
     ]
    }
   ],
   "source": [
    "#XG Boost estimator\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "# Define the SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "exe_role = 'arn:aws:iam::872515256694:role/service-role/AmazonSageMaker-ExecutionRole-20241012T210214'\n",
    "\n",
    "# Define the XGBoost estimator\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point='script.py',  # Path to your training script\n",
    "    role= exe_role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    framework_version='1.5-1',  # Use the version compatible with your code\n",
    "    base_job_name='xgboost-sagemaker',  # Base name for the training job\n",
    "    hyperparameters={\n",
    "        'n-estimators': 200,  # Best hyperparameter value\n",
    "        'learning-rate': 0.2,\n",
    "        'max-depth': 3,\n",
    "        'subsample': 0.8,\n",
    "        'gamma': 0.1,\n",
    "        'colsample-bytree': 1.0\n",
    "    },\n",
    "    use_spot_instances=True,  # Use spot instances to save costs\n",
    "    max_wait=7200,  # Maximum time to wait for spot instances\n",
    "    max_run=3600,   # Maximum time for the training job\n",
    ")\n",
    "\n",
    "# Launch the training job using the correct paths from your previous code\n",
    "xgb_estimator.fit({\"train\": train_s3_path, \"test\": test_s3_path}, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a75cc3e2-9700-4ea9-83f4-6f73f381d844",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.c5.large.\n",
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-11-20-03-18-36-310\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-11-20-03-18-36-818\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-11-20-03-18-36-818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!Endpoint created: sagemaker-xgboost-2024-11-20-03-18-36-818\n"
     ]
    }
   ],
   "source": [
    "#Endpoint Creation\n",
    "\n",
    "from sagemaker.xgboost import XGBoostModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# model artifact S3 path\n",
    "artifact_path = \"https://sagemaker-us-east-2-872515256694.s3.us-east-2.amazonaws.com/xgboost-sagemaker-2024-11-20-03-06-55-133/output/model.tar.gz\"\n",
    "\n",
    "\n",
    "# Create an XGBoost model\n",
    "model = XGBoostModel(\n",
    "    model_data=artifact_path,\n",
    "    role=get_execution_role(),  # Ensure you have the correct execution role\n",
    "    entry_point=\"script.py\",  # Path to your inference script\n",
    "    framework_version=\"1.5-1\",  # Match the version you used for training\n",
    ")\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "predictor = model.deploy(\n",
    "    instance_type=\"ml.c5.large\",  # Choose the instance type\n",
    "    initial_instance_count=1\n",
    ")\n",
    "\n",
    "print(\"Endpoint created:\", predictor.endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42593ec2-ed01-49f1-b734-91e09644cc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70a55325-4c09-4f5f-a1d7-fc501cd4f9d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted endpoint: sagemaker-xgboost-2024-11-20-03-10-24-501\n"
     ]
    }
   ],
   "source": [
    "#Delete Endpoint\n",
    "import boto3\n",
    "\n",
    "# Create a SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Specify your endpoint name\n",
    "endpoint_name = 'sagemaker-xgboost-2024-10-26-15-42-03-893'  # Replace with your endpoint name\n",
    "endpoint_name = predictor.endpoint_name\n",
    "\n",
    "# Delete the endpoint\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Deleted endpoint: {endpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb41239b-c45b-4b1c-b1f4-1c350bf7ad0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data send [[-1.651897076366327, 0.0, 0.4712277952726739, 0.0, 0.8506358319530646, 0.0, -0.289727944856067, -0.3576197377993809, 0.9444937469697804, 1.510315912095323, 0.5191904476506147, -0.813447391645092, -1.2496470844232883, 1.1883563314711472, 0.8991313612166442, 0.067867323135153, 0.3710710634780464, 0.0, 1.0, 1.0]]\n",
      "High Cost\n"
     ]
    }
   ],
   "source": [
    "# Test in \"local\" if the endpoint works\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "test_df = pd.read_csv(\"test_scaled.csv\")\n",
    "TARGET_NAME = \"price_range\"\n",
    "all_columns_name = [col for col in test_df.columns if col not in [TARGET_NAME, 'id', 'Unnamed: 0']]\n",
    "X_test = test_df[all_columns_name]\n",
    "\n",
    "aa = X_test.sample(1)\n",
    "data_send = str(aa.values.tolist())\n",
    "\n",
    "\n",
    "print(\"data send\", data_send)\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint,\n",
    "    Body=data_send,\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "\n",
    "result = response[\"Body\"].read().decode()\n",
    "\n",
    "equivalent = {0:\"Low Cost\",\n",
    "                  1:\"Medium Cost\",\n",
    "                  2:\"High Cost\",\n",
    "                  3:\"Very High Cost\"}\n",
    "                  \n",
    "predicted_label = equivalent[int(result[1])]\n",
    "    \n",
    "    \n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f0494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ea08acb-2d4c-4540-abc8-4d967af43691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Prediction: Low Cost\n",
      "Row 2 Prediction: High Cost\n",
      "Row 3 Prediction: Medium Cost\n",
      "Row 4 Prediction: Very High Cost\n",
      "Row 5 Prediction: Medium Cost\n",
      "Row 6 Prediction: Medium Cost\n",
      "Row 7 Prediction: High Cost\n",
      "Row 8 Prediction: Low Cost\n",
      "Row 9 Prediction: Very High Cost\n",
      "Row 10 Prediction: Medium Cost\n",
      "Row 11 Prediction: Low Cost\n",
      "Row 12 Prediction: Medium Cost\n",
      "Row 13 Prediction: High Cost\n",
      "Row 14 Prediction: Very High Cost\n",
      "Row 15 Prediction: High Cost\n",
      "Row 16 Prediction: High Cost\n",
      "Row 17 Prediction: Very High Cost\n",
      "Row 18 Prediction: Very High Cost\n",
      "Row 19 Prediction: Medium Cost\n",
      "Row 20 Prediction: Low Cost\n",
      "Row 21 Prediction: Low Cost\n",
      "Row 22 Prediction: Medium Cost\n",
      "Row 23 Prediction: Medium Cost\n",
      "Row 24 Prediction: High Cost\n",
      "Row 25 Prediction: Low Cost\n",
      "Row 26 Prediction: Medium Cost\n",
      "Row 27 Prediction: Very High Cost\n",
      "Row 28 Prediction: High Cost\n",
      "Row 29 Prediction: High Cost\n",
      "Row 30 Prediction: Low Cost\n",
      "Row 31 Prediction: Low Cost\n",
      "Row 32 Prediction: Low Cost\n",
      "Row 33 Prediction: Very High Cost\n",
      "Row 34 Prediction: Low Cost\n",
      "Row 35 Prediction: Medium Cost\n",
      "Row 36 Prediction: Medium Cost\n",
      "Row 37 Prediction: High Cost\n",
      "Row 38 Prediction: Low Cost\n",
      "Row 39 Prediction: Very High Cost\n",
      "Row 40 Prediction: Low Cost\n",
      "Row 41 Prediction: High Cost\n",
      "Row 42 Prediction: Very High Cost\n",
      "Row 43 Prediction: High Cost\n",
      "Row 44 Prediction: Low Cost\n",
      "Row 45 Prediction: Very High Cost\n",
      "Row 46 Prediction: High Cost\n",
      "Row 47 Prediction: Medium Cost\n",
      "Row 48 Prediction: Medium Cost\n",
      "Row 49 Prediction: Very High Cost\n",
      "Row 50 Prediction: Medium Cost\n",
      "Row 51 Prediction: Very High Cost\n",
      "Row 52 Prediction: Medium Cost\n",
      "Row 53 Prediction: Low Cost\n",
      "Row 54 Prediction: Low Cost\n",
      "Row 55 Prediction: Medium Cost\n",
      "Row 56 Prediction: Medium Cost\n",
      "Row 57 Prediction: Medium Cost\n",
      "Row 58 Prediction: High Cost\n",
      "Row 59 Prediction: Low Cost\n",
      "Row 60 Prediction: Low Cost\n",
      "Row 61 Prediction: Medium Cost\n",
      "Row 62 Prediction: Very High Cost\n",
      "Row 63 Prediction: Very High Cost\n",
      "Row 64 Prediction: Medium Cost\n",
      "Row 65 Prediction: Low Cost\n",
      "Row 66 Prediction: Low Cost\n",
      "Row 67 Prediction: Very High Cost\n",
      "Row 68 Prediction: Very High Cost\n",
      "Row 69 Prediction: Medium Cost\n",
      "Row 70 Prediction: High Cost\n",
      "Row 71 Prediction: High Cost\n",
      "Row 72 Prediction: High Cost\n",
      "Row 73 Prediction: Low Cost\n",
      "Row 74 Prediction: Medium Cost\n",
      "Row 75 Prediction: High Cost\n",
      "Row 76 Prediction: Low Cost\n",
      "Row 77 Prediction: Low Cost\n",
      "Row 78 Prediction: Very High Cost\n",
      "Row 79 Prediction: High Cost\n",
      "Row 80 Prediction: High Cost\n",
      "Row 81 Prediction: Very High Cost\n",
      "Row 82 Prediction: High Cost\n",
      "Row 83 Prediction: Medium Cost\n",
      "Row 84 Prediction: Low Cost\n",
      "Row 85 Prediction: Medium Cost\n",
      "Row 86 Prediction: Very High Cost\n",
      "Row 87 Prediction: Medium Cost\n",
      "Row 88 Prediction: Very High Cost\n",
      "Row 89 Prediction: Very High Cost\n",
      "Row 90 Prediction: Low Cost\n",
      "Row 91 Prediction: Very High Cost\n",
      "Row 92 Prediction: Very High Cost\n",
      "Row 93 Prediction: High Cost\n",
      "Row 94 Prediction: Medium Cost\n",
      "Row 95 Prediction: Very High Cost\n",
      "Row 96 Prediction: High Cost\n",
      "Row 97 Prediction: High Cost\n",
      "Row 98 Prediction: Very High Cost\n",
      "Row 99 Prediction: Medium Cost\n",
      "Row 100 Prediction: Medium Cost\n",
      "Row 101 Prediction: Low Cost\n",
      "Row 102 Prediction: Low Cost\n",
      "Row 103 Prediction: Medium Cost\n",
      "Row 104 Prediction: Low Cost\n",
      "Row 105 Prediction: Low Cost\n",
      "Row 106 Prediction: Very High Cost\n",
      "Row 107 Prediction: High Cost\n",
      "Row 108 Prediction: Low Cost\n",
      "Row 109 Prediction: Medium Cost\n",
      "Row 110 Prediction: Medium Cost\n",
      "Row 111 Prediction: Low Cost\n",
      "Row 112 Prediction: Low Cost\n",
      "Row 113 Prediction: Very High Cost\n",
      "Row 114 Prediction: Medium Cost\n",
      "Row 115 Prediction: Very High Cost\n",
      "Row 116 Prediction: High Cost\n",
      "Row 117 Prediction: Very High Cost\n",
      "Row 118 Prediction: Very High Cost\n",
      "Row 119 Prediction: Low Cost\n",
      "Row 120 Prediction: High Cost\n",
      "Row 121 Prediction: Medium Cost\n",
      "Row 122 Prediction: Very High Cost\n",
      "Row 123 Prediction: High Cost\n",
      "Row 124 Prediction: Medium Cost\n",
      "Row 125 Prediction: Very High Cost\n",
      "Row 126 Prediction: Very High Cost\n",
      "Row 127 Prediction: Low Cost\n",
      "Row 128 Prediction: Very High Cost\n",
      "Row 129 Prediction: Low Cost\n",
      "Row 130 Prediction: High Cost\n",
      "Row 131 Prediction: Very High Cost\n",
      "Row 132 Prediction: Low Cost\n",
      "Row 133 Prediction: High Cost\n",
      "Row 134 Prediction: High Cost\n",
      "Row 135 Prediction: Low Cost\n",
      "Row 136 Prediction: Very High Cost\n",
      "Row 137 Prediction: Medium Cost\n",
      "Row 138 Prediction: Low Cost\n",
      "Row 139 Prediction: Low Cost\n",
      "Row 140 Prediction: High Cost\n",
      "Row 141 Prediction: Very High Cost\n",
      "Row 142 Prediction: Low Cost\n",
      "Row 143 Prediction: Very High Cost\n",
      "Row 144 Prediction: High Cost\n",
      "Row 145 Prediction: Low Cost\n",
      "Row 146 Prediction: Low Cost\n",
      "Row 147 Prediction: Low Cost\n",
      "Row 148 Prediction: Medium Cost\n",
      "Row 149 Prediction: Medium Cost\n",
      "Row 150 Prediction: High Cost\n",
      "Row 151 Prediction: Very High Cost\n",
      "Row 152 Prediction: Medium Cost\n",
      "Row 153 Prediction: Medium Cost\n",
      "Row 154 Prediction: Low Cost\n",
      "Row 155 Prediction: High Cost\n",
      "Row 156 Prediction: High Cost\n",
      "Row 157 Prediction: Low Cost\n",
      "Row 158 Prediction: Medium Cost\n",
      "Row 159 Prediction: Low Cost\n",
      "Row 160 Prediction: Medium Cost\n",
      "Row 161 Prediction: High Cost\n",
      "Row 162 Prediction: Very High Cost\n",
      "Row 163 Prediction: High Cost\n",
      "Row 164 Prediction: High Cost\n",
      "Row 165 Prediction: Medium Cost\n",
      "Row 166 Prediction: Low Cost\n",
      "Row 167 Prediction: Low Cost\n",
      "Row 168 Prediction: High Cost\n",
      "Row 169 Prediction: High Cost\n",
      "Row 170 Prediction: Very High Cost\n",
      "Row 171 Prediction: Very High Cost\n",
      "Row 172 Prediction: Medium Cost\n",
      "Row 173 Prediction: Medium Cost\n",
      "Row 174 Prediction: Low Cost\n",
      "Row 175 Prediction: Very High Cost\n",
      "Row 176 Prediction: Medium Cost\n",
      "Row 177 Prediction: High Cost\n",
      "Row 178 Prediction: High Cost\n",
      "Row 179 Prediction: Medium Cost\n",
      "Row 180 Prediction: Low Cost\n",
      "Row 181 Prediction: Low Cost\n",
      "Row 182 Prediction: Low Cost\n",
      "Row 183 Prediction: Low Cost\n",
      "Row 184 Prediction: Low Cost\n",
      "Row 185 Prediction: Very High Cost\n",
      "Row 186 Prediction: High Cost\n",
      "Row 187 Prediction: Low Cost\n",
      "Row 188 Prediction: Very High Cost\n",
      "Row 189 Prediction: Low Cost\n",
      "Row 190 Prediction: Low Cost\n",
      "Row 191 Prediction: Low Cost\n",
      "Row 192 Prediction: Low Cost\n",
      "Row 193 Prediction: Medium Cost\n",
      "Row 194 Prediction: Very High Cost\n",
      "Row 195 Prediction: Very High Cost\n",
      "Row 196 Prediction: Medium Cost\n",
      "Row 197 Prediction: Low Cost\n",
      "Row 198 Prediction: Medium Cost\n",
      "Row 199 Prediction: Medium Cost\n",
      "Row 200 Prediction: Medium Cost\n",
      "Row 201 Prediction: Medium Cost\n",
      "Row 202 Prediction: Medium Cost\n",
      "Row 203 Prediction: High Cost\n",
      "Row 204 Prediction: High Cost\n",
      "Row 205 Prediction: Very High Cost\n",
      "Row 206 Prediction: Very High Cost\n",
      "Row 207 Prediction: Medium Cost\n",
      "Row 208 Prediction: High Cost\n",
      "Row 209 Prediction: Low Cost\n",
      "Row 210 Prediction: Low Cost\n",
      "Row 211 Prediction: Low Cost\n",
      "Row 212 Prediction: High Cost\n",
      "Row 213 Prediction: Medium Cost\n",
      "Row 214 Prediction: Medium Cost\n",
      "Row 215 Prediction: Very High Cost\n",
      "Row 216 Prediction: Medium Cost\n",
      "Row 217 Prediction: Low Cost\n",
      "Row 218 Prediction: High Cost\n",
      "Row 219 Prediction: Medium Cost\n",
      "Row 220 Prediction: Medium Cost\n",
      "Row 221 Prediction: Very High Cost\n",
      "Row 222 Prediction: High Cost\n",
      "Row 223 Prediction: Very High Cost\n",
      "Row 224 Prediction: Low Cost\n",
      "Row 225 Prediction: Low Cost\n",
      "Row 226 Prediction: High Cost\n",
      "Row 227 Prediction: Medium Cost\n",
      "Row 228 Prediction: Very High Cost\n",
      "Row 229 Prediction: Low Cost\n",
      "Row 230 Prediction: Medium Cost\n",
      "Row 231 Prediction: High Cost\n",
      "Row 232 Prediction: Low Cost\n",
      "Row 233 Prediction: High Cost\n",
      "Row 234 Prediction: Very High Cost\n",
      "Row 235 Prediction: High Cost\n",
      "Row 236 Prediction: Medium Cost\n",
      "Row 237 Prediction: Medium Cost\n",
      "Row 238 Prediction: Very High Cost\n",
      "Row 239 Prediction: Very High Cost\n",
      "Row 240 Prediction: Low Cost\n",
      "Row 241 Prediction: Medium Cost\n",
      "Row 242 Prediction: Very High Cost\n",
      "Row 243 Prediction: Very High Cost\n",
      "Row 244 Prediction: Very High Cost\n",
      "Row 245 Prediction: Low Cost\n",
      "Row 246 Prediction: Very High Cost\n",
      "Row 247 Prediction: Medium Cost\n",
      "Row 248 Prediction: High Cost\n",
      "Row 249 Prediction: Very High Cost\n",
      "Row 250 Prediction: Very High Cost\n",
      "Row 251 Prediction: High Cost\n",
      "Row 252 Prediction: Medium Cost\n",
      "Row 253 Prediction: Medium Cost\n",
      "Row 254 Prediction: Very High Cost\n",
      "Row 255 Prediction: Very High Cost\n",
      "Row 256 Prediction: Medium Cost\n",
      "Row 257 Prediction: Very High Cost\n",
      "Row 258 Prediction: Very High Cost\n",
      "Row 259 Prediction: Very High Cost\n",
      "Row 260 Prediction: Very High Cost\n",
      "Row 261 Prediction: Very High Cost\n",
      "Row 262 Prediction: Low Cost\n",
      "Row 263 Prediction: Medium Cost\n",
      "Row 264 Prediction: High Cost\n",
      "Row 265 Prediction: High Cost\n",
      "Row 266 Prediction: High Cost\n",
      "Row 267 Prediction: Very High Cost\n",
      "Row 268 Prediction: Low Cost\n",
      "Row 269 Prediction: High Cost\n",
      "Row 270 Prediction: Very High Cost\n",
      "Row 271 Prediction: High Cost\n",
      "Row 272 Prediction: High Cost\n",
      "Row 273 Prediction: High Cost\n",
      "Row 274 Prediction: Medium Cost\n",
      "Row 275 Prediction: Low Cost\n",
      "Row 276 Prediction: Medium Cost\n",
      "Row 277 Prediction: Low Cost\n",
      "Row 278 Prediction: High Cost\n",
      "Row 279 Prediction: Very High Cost\n",
      "Row 280 Prediction: Medium Cost\n",
      "Row 281 Prediction: Very High Cost\n",
      "Row 282 Prediction: Medium Cost\n",
      "Row 283 Prediction: Low Cost\n",
      "Row 284 Prediction: Very High Cost\n",
      "Row 285 Prediction: Medium Cost\n",
      "Row 286 Prediction: High Cost\n",
      "Row 287 Prediction: Low Cost\n",
      "Row 288 Prediction: Low Cost\n",
      "Row 289 Prediction: Very High Cost\n",
      "Row 290 Prediction: Low Cost\n",
      "Row 291 Prediction: Medium Cost\n",
      "Row 292 Prediction: High Cost\n",
      "Row 293 Prediction: Very High Cost\n",
      "Row 294 Prediction: Very High Cost\n",
      "Row 295 Prediction: Very High Cost\n",
      "Row 296 Prediction: Medium Cost\n",
      "Row 297 Prediction: Medium Cost\n",
      "Row 298 Prediction: Low Cost\n",
      "Row 299 Prediction: Medium Cost\n",
      "Row 300 Prediction: Very High Cost\n",
      "Row 301 Prediction: Very High Cost\n",
      "Row 302 Prediction: Low Cost\n",
      "Row 303 Prediction: Medium Cost\n",
      "Row 304 Prediction: High Cost\n",
      "Row 305 Prediction: High Cost\n",
      "Row 306 Prediction: Low Cost\n",
      "Row 307 Prediction: Very High Cost\n",
      "Row 308 Prediction: Very High Cost\n",
      "Row 309 Prediction: High Cost\n",
      "Row 310 Prediction: Very High Cost\n",
      "Row 311 Prediction: High Cost\n",
      "Row 312 Prediction: Very High Cost\n",
      "Row 313 Prediction: High Cost\n",
      "Row 314 Prediction: Low Cost\n",
      "Row 315 Prediction: High Cost\n",
      "Row 316 Prediction: Medium Cost\n",
      "Row 317 Prediction: Medium Cost\n",
      "Row 318 Prediction: Medium Cost\n",
      "Row 319 Prediction: Low Cost\n",
      "Row 320 Prediction: Low Cost\n",
      "Row 321 Prediction: Low Cost\n",
      "Row 322 Prediction: Very High Cost\n",
      "Row 323 Prediction: High Cost\n",
      "Row 324 Prediction: Very High Cost\n",
      "Row 325 Prediction: Medium Cost\n",
      "Row 326 Prediction: Low Cost\n",
      "Row 327 Prediction: Medium Cost\n",
      "Row 328 Prediction: Low Cost\n",
      "Row 329 Prediction: Medium Cost\n",
      "Row 330 Prediction: Very High Cost\n",
      "Row 331 Prediction: Very High Cost\n",
      "Row 332 Prediction: Low Cost\n",
      "Row 333 Prediction: Very High Cost\n",
      "Row 334 Prediction: Very High Cost\n",
      "Row 335 Prediction: High Cost\n",
      "Row 336 Prediction: Medium Cost\n",
      "Row 337 Prediction: Very High Cost\n",
      "Row 338 Prediction: Low Cost\n",
      "Row 339 Prediction: Low Cost\n",
      "Row 340 Prediction: Very High Cost\n",
      "Row 341 Prediction: Medium Cost\n",
      "Row 342 Prediction: Very High Cost\n",
      "Row 343 Prediction: High Cost\n",
      "Row 344 Prediction: Low Cost\n",
      "Row 345 Prediction: Medium Cost\n",
      "Row 346 Prediction: Medium Cost\n",
      "Row 347 Prediction: Medium Cost\n",
      "Row 348 Prediction: Medium Cost\n",
      "Row 349 Prediction: Medium Cost\n",
      "Row 350 Prediction: Very High Cost\n",
      "Row 351 Prediction: High Cost\n",
      "Row 352 Prediction: Low Cost\n",
      "Row 353 Prediction: Low Cost\n",
      "Row 354 Prediction: Very High Cost\n",
      "Row 355 Prediction: Very High Cost\n",
      "Row 356 Prediction: Low Cost\n",
      "Row 357 Prediction: Very High Cost\n",
      "Row 358 Prediction: Low Cost\n",
      "Row 359 Prediction: Low Cost\n",
      "Row 360 Prediction: High Cost\n",
      "Row 361 Prediction: Low Cost\n",
      "Row 362 Prediction: Medium Cost\n",
      "Row 363 Prediction: High Cost\n",
      "Row 364 Prediction: High Cost\n",
      "Row 365 Prediction: High Cost\n",
      "Row 366 Prediction: Very High Cost\n",
      "Row 367 Prediction: Low Cost\n",
      "Row 368 Prediction: High Cost\n",
      "Row 369 Prediction: High Cost\n",
      "Row 370 Prediction: High Cost\n",
      "Row 371 Prediction: Very High Cost\n",
      "Row 372 Prediction: Very High Cost\n",
      "Row 373 Prediction: Very High Cost\n",
      "Row 374 Prediction: High Cost\n",
      "Row 375 Prediction: Medium Cost\n",
      "Row 376 Prediction: Medium Cost\n",
      "Row 377 Prediction: Low Cost\n",
      "Row 378 Prediction: Very High Cost\n",
      "Row 379 Prediction: Medium Cost\n",
      "Row 380 Prediction: Very High Cost\n",
      "Row 381 Prediction: Very High Cost\n",
      "Row 382 Prediction: Low Cost\n",
      "Row 383 Prediction: High Cost\n",
      "Row 384 Prediction: Very High Cost\n",
      "Row 385 Prediction: High Cost\n",
      "Row 386 Prediction: Very High Cost\n",
      "Row 387 Prediction: Very High Cost\n",
      "Row 388 Prediction: Very High Cost\n",
      "Row 389 Prediction: Low Cost\n",
      "Row 390 Prediction: Low Cost\n",
      "Row 391 Prediction: High Cost\n",
      "Row 392 Prediction: Very High Cost\n",
      "Row 393 Prediction: Low Cost\n",
      "Row 394 Prediction: Low Cost\n",
      "Row 395 Prediction: High Cost\n",
      "Row 396 Prediction: Very High Cost\n",
      "Row 397 Prediction: High Cost\n",
      "Row 398 Prediction: Medium Cost\n",
      "Row 399 Prediction: Medium Cost\n",
      "Row 400 Prediction: High Cost\n"
     ]
    }
   ],
   "source": [
    "#Newtest\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize SageMaker runtime client\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"test_scaled.csv\")\n",
    "TARGET_NAME = \"price_range\"\n",
    "\n",
    "# Extract feature columns\n",
    "all_columns_name = [col for col in test_df.columns if col not in [TARGET_NAME, 'id', 'Unnamed: 0']]\n",
    "X_test = test_df[all_columns_name]\n",
    "\n",
    "# Define the mapping for predictions\n",
    "equivalent = {0: \"Low Cost\", 1: \"Medium Cost\", 2: \"High Cost\", 3: \"Very High Cost\"}\n",
    "\n",
    "# Iterate over each row and print predictions\n",
    "for index, row in X_test.iterrows():\n",
    "    # Convert row to a list and format as a CSV string\n",
    "    data_send = str([row.tolist()])\n",
    "\n",
    "    # Send data to the endpoint\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=predictor.endpoint_name,  # Updated to endpoint_name\n",
    "        Body=data_send,\n",
    "        ContentType=\"text/csv\",\n",
    "    )\n",
    "\n",
    "    # Decode the result and map to cost category\n",
    "    result = response[\"Body\"].read().decode()\n",
    "    predicted_label = equivalent[int(result[1])]  # Ensure the correct index for prediction\n",
    "    \n",
    "    # Print the prediction\n",
    "    print(f\"Row {index + 1} Prediction: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4f3d55a-568c-4583-94b2-874a4bb44520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction response: {'prediction': [3]}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize SageMaker runtime client\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Define your endpoint name\n",
    "ENDPOINT_NAME = predictor.endpoint_name # Replace with your SageMaker endpoint name\n",
    "\n",
    "# Define the raw input data\n",
    "raw_input_data = \"[[100, 0, 1, 0, 2, 0, 3, 50, 100, 200, 500, 4, 2, 6, 0, 0, 0, 0, 0, 0]]\"\n",
    "\n",
    "# Send the payload to the endpoint\n",
    "try:\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=raw_input_data,\n",
    "    )\n",
    "    \n",
    "    # Parse and print the response\n",
    "    result = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "    print(\"Prediction response:\", result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error invoking endpoint:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "085dfe57-b3dd-4def-9661-80752d6d0b81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending payload: [[100, 0, 1, 0, 2, 0, 3, 50, 100, 200, 500, 4, 2, 6, 0, 0, 0, 0, 0, 0], [300, 0, 2, 0, 3, 0, 6, 200, 400, 600, 800, 6, 3, 9, 0, 1, 0, 1, 0, 0], [700, 1, 4, 1, 5, 1, 8, 500, 800, 1000, 1200, 8, 4, 12, 1, 1, 1, 1, 0, 1]]\n",
      "Prediction response: {'prediction': [3, 3, 3]}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Define the endpoint name\n",
    "ENDPOINT_NAME = predictor.endpoint_name  # Replace this with your actual endpoint name\n",
    "\n",
    "# Define raw input data as a string of lists\n",
    "test_inputs = (\n",
    "    \"[[100, 0, 1, 0, 2, 0, 3, 50, 100, 200, 500, 4, 2, 6, 0, 0, 0, 0, 0, 0], \"\n",
    "    \"[300, 0, 2, 0, 3, 0, 6, 200, 400, 600, 800, 6, 3, 9, 0, 1, 0, 1, 0, 0], \"\n",
    "    \"[700, 1, 4, 1, 5, 1, 8, 500, 800, 1000, 1200, 8, 4, 12, 1, 1, 1, 1, 0, 1]]\"\n",
    ")\n",
    "\n",
    "print(\"Sending payload:\", test_inputs)\n",
    "\n",
    "try:\n",
    "    # Invoke the SageMaker endpoint\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=test_inputs,\n",
    "    )\n",
    "\n",
    "    # Decode and parse the response\n",
    "    result = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "    print(\"Prediction response:\", result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error invoking endpoint:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a227c8-bf98-4e8e-836d-2b4057b9a2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
